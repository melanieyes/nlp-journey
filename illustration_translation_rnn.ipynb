{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7efe5b00-cda0-4c3f-9cbc-6fd590ebb4a6",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22382432-34a8-474b-9519-af1168597ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7aaa78c-18e0-4e05-bfed-e22b1b7194bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tokenizer function\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "# Create a function to yield list of tokens\n",
    "def yield_tokens(examples):\n",
    "    for text in examples:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "# Tokenize and numericalize your samples\n",
    "def vectorize_en(text, vocab, sequence_length):\n",
    "    tokens = tokenizer(text)\n",
    "    tokens = [vocab[token] for token in tokens] + [vocab[\"<eos>\"]]\n",
    "    token_ids = tokens[:sequence_length] + [vocab[\"<pad>\"]] * (sequence_length - len(tokens))\n",
    "    return torch.tensor(token_ids, dtype=torch.long)\n",
    "\n",
    "# Tokenize and numericalize your samples\n",
    "def vectorize_vn(text, vocab, sequence_length):\n",
    "    tokens = tokenizer(text)\n",
    "    tokens = [vocab[\"<sos>\"]] + [vocab[token] for token in tokens] + [vocab[\"<eos>\"]]\n",
    "    token_ids = tokens[:sequence_length] + [vocab[\"<pad>\"]] * (sequence_length - len(tokens))\n",
    "    return torch.tensor(token_ids, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a84e42f-922c-4060-a00b-85dd862b1e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_en = [\n",
    "    \"learning english\",\n",
    "    \"build ai model\"    \n",
    "]\n",
    "data_size_en = len(corpus_en)\n",
    "\n",
    "# max vocabulary size and sequence length\n",
    "vocab_size_en = 8\n",
    "sequence_length_en = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "838ccb88-1930-47ba-8536-c97bb58b9fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 7,\n",
       " 'learning': 6,\n",
       " 'english': 5,\n",
       " 'build': 4,\n",
       " 'ai': 3,\n",
       " '<eos>': 2,\n",
       " '<pad>': 1,\n",
       " '<unk>': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create vocabulary\n",
    "vocab_en = build_vocab_from_iterator(yield_tokens(corpus_en),\n",
    "                                     max_tokens=vocab_size_en,\n",
    "                                     specials=[\"<unk>\", \"<pad>\", \"<eos>\"])\n",
    "vocab_en.set_default_index(vocab_en[\"<unk>\"])\n",
    "vocab_en.get_stoi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53c1877c-fd26-4a6f-9bd3-ff50a1e3ab0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 5, 2, 1])\n",
      "tensor([4, 3, 7, 2])\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the samples\n",
    "corpus_ids_en = []\n",
    "for sentence in corpus_en:\n",
    "    corpus_ids_en.append(vectorize_en(sentence, vocab_en, sequence_length_en))\n",
    "\n",
    "# print\n",
    "for v in corpus_ids_en:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "164459c8-b226-447a-8a69-4a12e05e7566",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_vn = [\n",
    "    \"học tiếng anh\",\n",
    "    \"xây mô hình ai\"    \n",
    "]\n",
    "data_size_vn = len(corpus_vn)\n",
    "\n",
    "# max vocabulary size and sequence length\n",
    "vocab_size_vn = 12\n",
    "sequence_length_vn = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2726650a-52ef-4150-9b09-0071d0ce2a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tiếng': 9,\n",
       " 'học': 7,\n",
       " 'anh': 5,\n",
       " '<sos>': 2,\n",
       " 'xây': 10,\n",
       " 'mô': 8,\n",
       " 'hình': 6,\n",
       " 'ai': 4,\n",
       " '<eos>': 3,\n",
       " '<pad>': 1,\n",
       " '<unk>': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create vocabulary\n",
    "vocab_vn = build_vocab_from_iterator(yield_tokens(corpus_vn),\n",
    "                                  max_tokens=vocab_size_vn,\n",
    "                                  specials=[\"<unk>\", \"<pad>\", \"<sos>\", \"<eos>\"])\n",
    "vocab_vn.set_default_index(vocab_vn[\"<unk>\"])\n",
    "vocab_vn.get_stoi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "548484cb-e415-4e4f-a7f5-b0fd0ed48e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 7, 9, 5, 3, 1])\n",
      "tensor([ 2, 10,  8,  6,  4,  3])\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the samples\n",
    "corpus_ids_vn = []\n",
    "for sentence in corpus_vn:\n",
    "    corpus_ids_vn.append(vectorize_vn(sentence, vocab_vn, sequence_length_vn))\n",
    "\n",
    "# print\n",
    "for v in corpus_ids_vn:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b547154b-2223-4e4f-a875-119ec33f9812",
   "metadata": {},
   "source": [
    "## Train with full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72f159d4-4a24-4cd2-bd45-853802e1ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size_en, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size_en, embedding_dim)\n",
    "        self.custom_weights = torch.tensor([[-0.1,  0.5],\n",
    "                                            [ 1.7, -0.8],\n",
    "                                            [ 1.0, -1.9],\n",
    "                                            [-1.3, -0.1],\n",
    "                                            [ 0.2,  1.3],\n",
    "                                            [ 0.4, -0.6],\n",
    "                                            [ 0.5,  0.1],\n",
    "                                            [ 0.4, -1.3]]).float()\n",
    "        self.embedding.weight = nn.Parameter(self.custom_weights)\n",
    "\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.rnn.bias_ih_l0 = nn.Parameter(torch.tensor([0.4,  0.5, 0.2]).float())\n",
    "        self.rnn.bias_hh_l0 = nn.Parameter(torch.tensor([ 0.1, -0.2, 0.1]).float())\n",
    "        self.rnn.weight_ih_l0 = nn.Parameter(torch.tensor( [[-0.4,  0.1],\n",
    "                                                            [ 0.4, -0.4],\n",
    "                                                            [ 0.1, 0.2]]).float())\n",
    "        self.rnn.weight_hh_l0 = nn.Parameter(torch.tensor( [[-0.5,  0.1, 0.1],\n",
    "                                                            [-0.2, -0.2, 0.1],\n",
    "                                                            [-0.2, -0.2, 0.2]]).float())\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src)     \n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c940aa66-82d6-448e-a349-2ed223cd065c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sample = torch.tensor([[6, 5, 2, 1]], dtype=torch.long)\n",
    "\n",
    "embedding_dim, hidden_dim = 2, 3\n",
    "encoder = Encoder(vocab_size_en, embedding_dim, hidden_dim)\n",
    "\n",
    "outputs, hidden = encoder(input_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39687bf5-3741-4910-8444-c89358bc81f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size_vn, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(vocab_size_vn, embedding_dim)\n",
    "        self.custom_weights = torch.tensor([[ 0.3, -0.7],\n",
    "                                            [-1.1,  0.9],\n",
    "                                            [ 0.8, -1.4],\n",
    "                                            [-0.5,  0.2],\n",
    "                                            [ 1.2, -0.3],\n",
    "                                            [-0.9,  1.5],\n",
    "                                            [ 0.6, -0.2],\n",
    "                                            [-1.7,  0.4],\n",
    "                                            [ 0.2,  1.1],\n",
    "                                            [-1.0,  0.8],\n",
    "                                            [ 1.4, -1.2],\n",
    "                                            ]).float()\n",
    "        self.embedding.weight = nn.Parameter(self.custom_weights)\n",
    "\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.rnn.bias_ih_l0 = nn.Parameter(torch.tensor([0.3, -0.1, 0.6]).float())\n",
    "        self.rnn.bias_hh_l0 = nn.Parameter(torch.tensor([-0.2, 0.4, -0.3]).float())\n",
    "        self.rnn.weight_ih_l0 = nn.Parameter(torch.tensor([[0.2, -0.3],\n",
    "                                                            [-0.5,  0.6],\n",
    "                                                            [ 0.1,  0.4]]).float())\n",
    "        self.rnn.weight_hh_l0 = nn.Parameter(torch.tensor([[-0.3,  0.2, -0.4],\n",
    "                                                            [ 0.5, -0.1,  0.3],\n",
    "                                                            [ 0.2, -0.5,  0.1]]).float())\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input)     \n",
    "        output, hidden = self.rnn(embedded, hidden)        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ae940e0-e7bf-43c3-af4c-45ea79ffac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sample = torch.tensor([[2, 7, 9]], dtype=torch.long)   # [[2, 6, 5, 8, 3]]\n",
    "decoder = Decoder(vocab_size_vn, embedding_dim, hidden_dim)\n",
    "\n",
    "prediction, hidden= decoder(target_sample, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0eb95237-d3b6-4f42-9f3e-25aadd967a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq_Model(nn.Module):\n",
    "    def __init__(self, encoder, decoder, vocab_size_vn):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder \n",
    "        self.fc_out = nn.Linear(decoder.hidden_dim, vocab_size_vn)\n",
    "        self.fc_out.weight = nn.Parameter(torch.tensor([[-0.52,  0.25, -0.35],\n",
    "                                                        [ 0.06, -0.16,  0.18],\n",
    "                                                        [-0.52,  0.33,  0.02],\n",
    "                                                        [-0.12, -0.57, -0.4],\n",
    "                                                        [-0.18, -0.5, -0.01],\n",
    "                                                        [ 0.35, -0.03,  0.46],\n",
    "                                                        [-0.13,  0.16,  0.23],\n",
    "                                                        [-0.99,  0.31, -0.24],\n",
    "                                                        [-0.74, -0.25,  0.5],\n",
    "                                                        [-0.44, -0.02, -0.39],\n",
    "                                                        [-0.35, -0.43,  0.35],\n",
    "                                                        [ 0.26, -0.49,  0.09]]).float())\n",
    "        self.fc_out.bias = nn.Parameter(torch.tensor([0.12, -0.21, -0.15, \n",
    "                                                      -0.54,  0.36,  0.49,  \n",
    "                                                      0.49,  0.07, 0.23,  \n",
    "                                                      0.52,  0.29, -0.27]).float())\n",
    "\n",
    "    def forward(self, sequence_en, sequence_vn):\n",
    "        en_output, en_hidden = self.encoder(sequence_en)\n",
    "        de_output, de_hidden = self.decoder(sequence_vn, en_hidden)\n",
    "        outputs = self.fc_out(de_hidden.squeeze(0))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7cb8b50-51a1-43b1-9d2d-569c269e3ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq_Model(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(8, 2)\n",
      "    (rnn): RNN(2, 3, batch_first=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(12, 2)\n",
      "    (rnn): RNN(2, 3, batch_first=True)\n",
      "  )\n",
      "  (fc_out): Linear(in_features=3, out_features=12, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Seq2Seq_Model(encoder, decoder, vocab_size_vn)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1367b830-30f1-43e1-bef1-e896633345ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.5245e-01, -3.5172e-01,  2.5774e-01, -9.8450e-01, -9.5534e-04,\n",
      "          3.8520e-01,  6.6128e-01,  5.7886e-01,  2.3522e-01,  6.0968e-01,\n",
      "          4.0912e-02, -7.3660e-01]], grad_fn=<AddmmBackward0>)\n",
      "tensor([6])\n"
     ]
    }
   ],
   "source": [
    "en_sample = torch.tensor([[6, 5, 2, 1]], dtype=torch.long)\n",
    "vn_sample = torch.tensor([[2, 7, 9]], dtype=torch.long)\n",
    "target = torch.tensor([6], dtype=torch.long)\n",
    "\n",
    "outputs = model(en_sample, vn_sample)\n",
    "print((outputs))\n",
    "\n",
    "prediction = torch.argmax(outputs, dim=1)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32ed2deb-b3e3-4a70-8b85-c575001fc213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0306, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "loss = criterion(outputs, target)\n",
    "print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7efe5b00-cda0-4c3f-9cbc-6fd590ebb4a6",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22382432-34a8-474b-9519-af1168597ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext; torchtext.disable_torchtext_deprecation_warning()\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7aaa78c-18e0-4e05-bfed-e22b1b7194bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tokenizer function\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "# Create a function to yield list of tokens\n",
    "def yield_tokens(examples):\n",
    "    for text in examples:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "# Tokenize and numericalize your samples\n",
    "def vectorize_en(text, vocab, sequence_length):\n",
    "    tokens = tokenizer(text)\n",
    "    tokens = [vocab[token] for token in tokens] + [vocab[\"<eos>\"]]\n",
    "    token_ids = tokens[:sequence_length] + [vocab[\"<pad>\"]] * (sequence_length - len(tokens))\n",
    "    return token_ids\n",
    "\n",
    "def vectorize_vn(text, vocab, sequence_length):\n",
    "    tokens = tokenizer(text)\n",
    "    tokens = [vocab[\"<sos>\"]] + [vocab[token] for token in tokens] + [vocab[\"<eos>\"]]\n",
    "    token_ids = tokens[:sequence_length] + [vocab[\"<pad>\"]] * (sequence_length - len(tokens))\n",
    "    return token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b52f74-b11f-4edc-9dc1-af4d396cce68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a84e42f-922c-4060-a00b-85dd862b1e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_en = [\n",
    "    \"good morning\",\n",
    "    \"ai books\"    \n",
    "]\n",
    "data_size_en = len(corpus_en)\n",
    "\n",
    "# max vocabulary size and sequence length\n",
    "vocab_size_en = 7\n",
    "sequence_length_en = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "838ccb88-1930-47ba-8536-c97bb58b9fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'morning': 6,\n",
       " 'good': 5,\n",
       " 'books': 4,\n",
       " 'ai': 3,\n",
       " '<eos>': 2,\n",
       " '<pad>': 1,\n",
       " '<unk>': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create vocabulary\n",
    "vocab_en = build_vocab_from_iterator(yield_tokens(corpus_en),\n",
    "                                     max_tokens=vocab_size_en,\n",
    "                                     specials=[\"<unk>\", \"<pad>\", \"<eos>\"])\n",
    "vocab_en.set_default_index(vocab_en[\"<unk>\"])\n",
    "vocab_en.get_stoi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53c1877c-fd26-4a6f-9bd3-ff50a1e3ab0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 6, 2],\n",
      "        [3, 4, 2]])\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the samples\n",
    "corpus_ids_en = []\n",
    "for sentence in corpus_en:\n",
    "    corpus_ids_en.append(vectorize_en(sentence, vocab_en, sequence_length_en))\n",
    "\n",
    "# print\n",
    "en_data = torch.tensor(corpus_ids_en, dtype=torch.long)\n",
    "print(en_data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cd8bc9-09c2-4d48-9df7-58509f5a5844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aa36c0-0f64-4fdd-80f9-26a508c0c250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "164459c8-b226-447a-8a69-4a12e05e7566",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_vn = [\n",
    "    \"chào buổi sáng\",\n",
    "    \"sách ai\"    \n",
    "]\n",
    "data_size_vn = len(corpus_vn)\n",
    "\n",
    "# max vocabulary size and sequence length\n",
    "vocab_size_vn = 9\n",
    "sequence_length_vn = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2726650a-52ef-4150-9b09-0071d0ce2a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sách': 7,\n",
       " 'sáng': 8,\n",
       " 'chào': 6,\n",
       " 'buổi': 5,\n",
       " '<sos>': 2,\n",
       " 'ai': 4,\n",
       " '<eos>': 3,\n",
       " '<pad>': 1,\n",
       " '<unk>': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create vocabulary\n",
    "vocab_vn = build_vocab_from_iterator(yield_tokens(corpus_vn),\n",
    "                                  max_tokens=vocab_size_vn,\n",
    "                                  specials=[\"<unk>\", \"<pad>\", \"<sos>\", \"<eos>\"])\n",
    "vocab_vn.set_default_index(vocab_vn[\"<unk>\"])\n",
    "vocab_vn.get_stoi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "548484cb-e415-4e4f-a7f5-b0fd0ed48e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 6, 5, 8, 3], [2, 7, 4, 3, 1]]\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the samples\n",
    "corpus_ids_vn = []\n",
    "for sentence in corpus_vn:\n",
    "    corpus_ids_vn.append(vectorize_vn(sentence, vocab_vn, sequence_length_vn+1))\n",
    "\n",
    "# print\n",
    "print(corpus_ids_vn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57fe0f68-dca5-46f8-84db-62561b899b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 6, 5, 8],\n",
      "        [2, 7, 4, 3]])\n",
      "tensor([[6, 5, 8, 3],\n",
      "        [7, 4, 3, 1]])\n"
     ]
    }
   ],
   "source": [
    "input_vn_data = []\n",
    "label_vn_data = []\n",
    "\n",
    "for vector in corpus_ids_vn:\n",
    "    input_vn_data.append(vector[:-1])\n",
    "    label_vn_data.append(vector[1:])  \n",
    "\n",
    "# convert to tensors\n",
    "input_vn_data = torch.tensor(input_vn_data, dtype=torch.long)\n",
    "label_vn_data = torch.tensor(label_vn_data, dtype=torch.long)\n",
    "\n",
    "# print\n",
    "print(input_vn_data)\n",
    "print(label_vn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c610df2e-db78-4110-b8e5-2df61ffbff24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b547154b-2223-4e4f-a875-119ec33f9812",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acc281f2-af38-4b58-8d62-d35287203e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size_en, embedding_dim, model_dim, nhead):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size_en, embedding_dim)\n",
    "        self.transformer_encoder = nn.TransformerEncoderLayer(d_model=model_dim, \n",
    "                                                              nhead=nhead, \n",
    "                                                              dim_feedforward=6,\n",
    "                                                              dropout=0.0,\n",
    "                                                              batch_first=True)\n",
    "\n",
    "    # src = [batch_size, seq_length]\n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src)                # [batch_size, seq_length, d]        \n",
    "        context = self.transformer_encoder(embedded)  # [batch_size, seq_length, d]         \n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198e1e8e-d01e-48d5-9b1b-68951feea924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ea30ddb-7391-48ba-903e-e12d773fd6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c940aa66-82d6-448e-a349-2ed223cd065c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "embedding_dim, model_dim, nhead = 6, 6, 2\n",
    "encoder = Encoder(vocab_size_en, embedding_dim, model_dim, nhead)\n",
    "\n",
    "context_sample = encoder(en_data)\n",
    "print(context_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e38434-1d7a-4c22-b278-ec03481377ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39687bf5-3741-4910-8444-c89358bc81f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size_vn, embedding_dim, model_dim, nhead, sequence_length_vn):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size_vn, embedding_dim)\n",
    "        self.mask = torch.triu(torch.ones(sequence_length_vn, sequence_length_vn), diagonal=1).bool()  \n",
    "        self.transformer_decoder = nn.TransformerDecoderLayer(d_model=model_dim, \n",
    "                                                              nhead=nhead, \n",
    "                                                              dim_feedforward=6,\n",
    "                                                              dropout=0.0,\n",
    "                                                              batch_first=True)\n",
    "        self.fc_out = nn.Linear(model_dim, vocab_size_vn)\n",
    "\n",
    "    # input: [batch_size, seq_length_vn]   \n",
    "    # context: [batch_size, seq_length_en, d]\n",
    "    def forward(self, input, context):                \n",
    "        embedded = self.embedding(input)                                           # [batch_size, seq_length_vn, d]        \n",
    "        output = self.transformer_decoder(embedded, context, tgt_mask=self.mask)   # [batch_size, seq_length_vn, d]        \n",
    "        prediction = self.fc_out(output)                                           # [batch_size, seq_length_vn, vocab_size_vn]\n",
    "        \n",
    "        return prediction.permute(0, 2, 1)                                         # [batch_size, vocab_size_vn, seq_length_vn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ae940e0-e7bf-43c3-af4c-45ea79ffac7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9, 4])\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_size_vn, embedding_dim, model_dim, nhead, sequence_length_vn)\n",
    "outputs = decoder(input_vn_data, context_sample)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a328c8e3-1ed9-4df0-9bc5-f65a0871c47b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0eb95237-d3b6-4f42-9f3e-25aadd967a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq_Model(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder     \n",
    "\n",
    "    def forward(self, sequence_en, sequence_vn):        \n",
    "        context = self.encoder(sequence_en)\n",
    "        outputs = self.decoder(sequence_vn, context)            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7cb8b50-51a1-43b1-9d2d-569c269e3ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9, 4])\n"
     ]
    }
   ],
   "source": [
    "model = Seq2Seq_Model(encoder, decoder)\n",
    "\n",
    "# test\n",
    "outputs = model(en_data, input_vn_data)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2243a16b-fca5-43e2-b86e-d7530b304f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_vn_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e7f7fe-8ca3-4605-a880-fec337413832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80d072cc-ab43-4817-8bab-2dfc056d72ea",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32ed2deb-b3e3-4a70-8b85-c575001fc213",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910680f9-acb5-493e-a194-a3f18f4788f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbee29f3-5988-4f5f-a9f1-fb13f137a91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.572211980819702\n",
      "2.0582990646362305\n",
      "1.8298975229263306\n",
      "1.6489864587783813\n",
      "1.452692985534668\n",
      "1.3585753440856934\n",
      "1.2285832166671753\n",
      "1.0857281684875488\n",
      "0.884067714214325\n",
      "0.8026986718177795\n",
      "0.6825419664382935\n",
      "0.5574626922607422\n",
      "0.4896906614303589\n",
      "0.4031267464160919\n",
      "0.3443576395511627\n",
      "0.26172083616256714\n",
      "0.2054610550403595\n",
      "0.14212802052497864\n",
      "0.10413385927677155\n",
      "0.07778821885585785\n",
      "0.05209149792790413\n",
      "0.03987732529640198\n",
      "0.0316433347761631\n",
      "0.022833406925201416\n",
      "0.01573421061038971\n",
      "0.013697528280317783\n",
      "0.012465091422200203\n",
      "0.010541660711169243\n",
      "0.008088898845016956\n",
      "0.006039146799594164\n",
      "0.004743597470223904\n",
      "0.004063807427883148\n",
      "0.003617584239691496\n",
      "0.0032029422000050545\n",
      "0.0029022207017987967\n"
     ]
    }
   ],
   "source": [
    "for _ in range(35):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(en_data, input_vn_data)\n",
    "    loss = criterion(outputs, label_vn_data)\n",
    "    print(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b562b790-b1f8-4e0c-a1cc-2453ee3f3a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 5, 8, 3],\n",
      "        [7, 4, 3, 1]])\n"
     ]
    }
   ],
   "source": [
    "outputs = model(en_data, input_vn_data)\n",
    "print(torch.argmax(outputs, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "051f948f-3123-43f0-8e9d-ec8315314d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6, 5, 8, 3],\n",
       "        [7, 4, 3, 1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_vn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f519bd6-a4f9-4037-bea8-bf7118e684f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7efe5b00-cda0-4c3f-9cbc-6fd590ebb4a6",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22382432-34a8-474b-9519-af1168597ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38ad3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56f7209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_en = [\n",
    "    \"good morning\",\n",
    "    \"ai books\"    \n",
    "]\n",
    "\n",
    "# max vocabulary size and sequence length\n",
    "vocab_size_en = 7\n",
    "sequence_length_en = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69a42872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer and define a trainer\n",
    "tokenizer_en = Tokenizer(WordLevel())\n",
    "tokenizer_en.pre_tokenizer = Whitespace()\n",
    "tokenizer_en.enable_padding(pad_id=1, \n",
    "                                    pad_token=\"<pad>\", \n",
    "                                    length=sequence_length_en)\n",
    "tokenizer_en.enable_truncation(max_length=sequence_length_en)\n",
    "\n",
    "# Train the tokenizer on your corpus\n",
    "trainer_generation = WordLevelTrainer(vocab_size=vocab_size_en, \n",
    "                                      special_tokens=[\"<unk>\", \"<pad>\", \"<eos>\"])\n",
    "tokenizer_en.train_from_iterator(corpus_en, trainer_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "951adfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 6, 1],\n",
      "        [3, 4, 1]])\n",
      "{'<unk>': 0, 'good': 5, 'morning': 6, '<eos>': 2, 'books': 4, 'ai': 3, '<pad>': 1}\n"
     ]
    }
   ],
   "source": [
    "topics_ids = []\n",
    "for x in corpus_en:\n",
    "    x_ids = tokenizer_en.encode(x).ids\n",
    "    topics_ids.append(x_ids)\n",
    "\n",
    "en_data = torch.tensor(topics_ids, dtype=torch.long)\n",
    "\n",
    "print(en_data)\n",
    "print(tokenizer_en.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8691eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12ad3c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_vn = [\n",
    "    \"chào buổi sáng\",\n",
    "    \"sách ai\"    \n",
    "]\n",
    "\n",
    "# max vocabulary size and sequence length\n",
    "vocab_size_vn = 9\n",
    "sequence_length_vn = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "438fb24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer and define a trainer\n",
    "tokenizer_vn = Tokenizer(WordLevel())\n",
    "tokenizer_vn.pre_tokenizer = Whitespace()\n",
    "tokenizer_vn.enable_padding(pad_id=1, \n",
    "                            pad_token=\"<pad>\", \n",
    "                            length=sequence_length_vn)\n",
    "tokenizer_vn.enable_truncation(max_length=sequence_length_vn)\n",
    "\n",
    "# Train the tokenizer on your corpus\n",
    "trainer_vn = WordLevelTrainer(vocab_size=vocab_size_vn, \n",
    "                              special_tokens=[\"<unk>\", \"<pad>\", \"<sos>\", \"<eos>\"])\n",
    "tokenizer_vn.train_from_iterator(corpus_vn, trainer_vn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b002a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<sos> chào buổi sáng', '<sos> sách ai']\n",
      "['chào buổi sáng <eos>', 'sách ai <eos>']\n"
     ]
    }
   ],
   "source": [
    "data_x = []\n",
    "data_y = []\n",
    "for vector in corpus_vn:\n",
    "    vector = ['<sos>'] + vector.split() + ['<eos>']\n",
    "    data_x.append( ' '.join(vector[:-1]) )\n",
    "    data_y.append( ' '.join(vector[1:]) )\n",
    "\n",
    "print(data_x)\n",
    "print(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c610df2e-db78-4110-b8e5-2df61ffbff24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 6, 5, 8] [6, 5, 8, 3]\n",
      "[2, 7, 4, 1] [7, 4, 3, 1]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and numericalize your samples\n",
    "def vectorize_generation(x, y, tokenizer_vn):     \n",
    "    x_ids = tokenizer_vn.encode(x).ids\n",
    "    y_ids = tokenizer_vn.encode(y).ids\n",
    "    print(x_ids, y_ids)\n",
    "    return x_ids, y_ids\n",
    "\n",
    "# Vectorize the samples\n",
    "input_vn_data = []\n",
    "label_vn_data = []\n",
    "for x, y in zip(data_x, data_y):\n",
    "    x_ids, y_ids = vectorize_generation(x, y, tokenizer_vn)\n",
    "    input_vn_data.append(x_ids)\n",
    "    label_vn_data.append(y_ids)\n",
    "\n",
    "input_vn_data = torch.tensor(input_vn_data, dtype=torch.long)\n",
    "label_vn_data = torch.tensor(label_vn_data, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b547154b-2223-4e4f-a875-119ec33f9812",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acc281f2-af38-4b58-8d62-d35287203e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size_en, embedding_dim, model_dim, nhead):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size_en, embedding_dim)\n",
    "        self.transformer_encoder = nn.TransformerEncoderLayer(d_model=model_dim, \n",
    "                                                              nhead=nhead, \n",
    "                                                              dim_feedforward=6,\n",
    "                                                              dropout=0.0,\n",
    "                                                              batch_first=True)\n",
    "\n",
    "    # src = [batch_size, seq_length]\n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src)                # [batch_size, seq_length, d]        \n",
    "        context = self.transformer_encoder(embedded)  # [batch_size, seq_length, d]         \n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198e1e8e-d01e-48d5-9b1b-68951feea924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ea30ddb-7391-48ba-903e-e12d773fd6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c940aa66-82d6-448e-a349-2ed223cd065c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "embedding_dim, model_dim, nhead = 6, 6, 2\n",
    "encoder = Encoder(vocab_size_en, embedding_dim, model_dim, nhead)\n",
    "\n",
    "context_sample = encoder(en_data)\n",
    "print(context_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e38434-1d7a-4c22-b278-ec03481377ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39687bf5-3741-4910-8444-c89358bc81f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size_vn, embedding_dim, model_dim, nhead, sequence_length_vn):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size_vn, embedding_dim)\n",
    "        self.mask = torch.triu(torch.ones(sequence_length_vn, sequence_length_vn), diagonal=1).bool()  \n",
    "        self.transformer_decoder = nn.TransformerDecoderLayer(d_model=model_dim, \n",
    "                                                              nhead=nhead, \n",
    "                                                              dim_feedforward=6,\n",
    "                                                              dropout=0.0,\n",
    "                                                              batch_first=True)\n",
    "        self.fc_out = nn.Linear(model_dim, vocab_size_vn)\n",
    "\n",
    "    # input: [batch_size, seq_length_vn]   \n",
    "    # context: [batch_size, seq_length_en, d]\n",
    "    def forward(self, input, context):                \n",
    "        embedded = self.embedding(input)                                           # [batch_size, seq_length_vn, d]        \n",
    "        output = self.transformer_decoder(embedded, context, tgt_mask=self.mask)   # [batch_size, seq_length_vn, d]        \n",
    "        prediction = self.fc_out(output)                                           # [batch_size, seq_length_vn, vocab_size_vn]\n",
    "        \n",
    "        return prediction.permute(0, 2, 1)                                         # [batch_size, vocab_size_vn, seq_length_vn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ae940e0-e7bf-43c3-af4c-45ea79ffac7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9, 4])\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_size_vn, embedding_dim, model_dim, nhead, sequence_length_vn)\n",
    "outputs = decoder(input_vn_data, context_sample)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a328c8e3-1ed9-4df0-9bc5-f65a0871c47b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0eb95237-d3b6-4f42-9f3e-25aadd967a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq_Model(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder     \n",
    "\n",
    "    def forward(self, sequence_en, sequence_vn):        \n",
    "        context = self.encoder(sequence_en)\n",
    "        outputs = self.decoder(sequence_vn, context)            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7cb8b50-51a1-43b1-9d2d-569c269e3ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9, 4])\n"
     ]
    }
   ],
   "source": [
    "model = Seq2Seq_Model(encoder, decoder)\n",
    "\n",
    "# test\n",
    "outputs = model(en_data, input_vn_data)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d072cc-ab43-4817-8bab-2dfc056d72ea",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32ed2deb-b3e3-4a70-8b85-c575001fc213",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbee29f3-5988-4f5f-a9f1-fb13f137a91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(en_data, input_vn_data)\n",
    "    loss = criterion(outputs, label_vn_data)\n",
    "    #print(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b562b790-b1f8-4e0c-a1cc-2453ee3f3a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 5, 8, 3],\n",
      "        [7, 4, 3, 1]])\n"
     ]
    }
   ],
   "source": [
    "outputs = model(en_data, input_vn_data)\n",
    "print(torch.argmax(outputs, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "051f948f-3123-43f0-8e9d-ec8315314d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6, 5, 8, 3],\n",
       "        [7, 4, 3, 1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_vn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f519bd6-a4f9-4037-bea8-bf7118e684f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
